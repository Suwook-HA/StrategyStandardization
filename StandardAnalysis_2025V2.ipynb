{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aca202a-e046-431e-a442-6f0c5458e30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™”ì¼ì˜ ë°ì´í„° í–‰ìˆ˜ ==> 650\n",
      "ğŸ›‘ ê°œë°œ ì¤‘ë‹¨ëœ í”„ë¡œì íŠ¸ ìˆ˜: 4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'astype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 259\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    258\u001b[0m     data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 259\u001b[0m     main(data_dir)\n",
      "Cell \u001b[1;32mIn[29], line 195\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m    193\u001b[0m grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm_capability\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin())\n\u001b[0;32m    194\u001b[0m grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì¢…í•©í™œë™ ì ìˆ˜\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm_dev_stage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm_capability\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 195\u001b[0m grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì¢…í•©í™œë™ ì ìˆ˜(5ì ì²™ë„)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (grouped15[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì¢…í•©í™œë™ ì ìˆ˜\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m0\u001b[39m),astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    197\u001b[0m grouped_dfs\u001b[38;5;241m.\u001b[39mappend((grouped15, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m42ëŒ€ì¤‘ì _ì „ëµ\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# Excel íŒŒì¼ í†µí•© ì €ì¥\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'astype' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import platform\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Outputs í´ë” ìƒì„± + ë‚ ì§œ/ì‹œê°„ë³„ í•˜ìœ„ í´ë” ìƒì„±\n",
    "output_root = \"Outputs\"\n",
    "now_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "output_dir = os.path.join(output_root, now_str)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def save_figure(plt_obj, filename):\n",
    "    \"\"\"plt ê°ì²´ë¥¼ ë‚ ì§œ/ì‹œê°„ë³„ í´ë”ì— ê·¸ë¦¼ìœ¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    full_path = os.path.join(output_dir, f\"{filename}.jpg\")\n",
    "    plt_obj.savefig(full_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"âœ… ê·¸ë¦¼ ì €ì¥ ì™„ë£Œ: {full_path}\")\n",
    "\n",
    "# ê³ ìœ  ì˜ì¥ë‹¨ìˆ˜ ê³„ì‚° í•¨ìˆ˜\n",
    "def count_unique_names(text):\n",
    "    \"\"\"ì§ì±…(ì´ë¦„) íŒ¨í„´ìœ¼ë¡œ ê³ ìœ  í•­ëª© ì¶”ì¶œ í›„ ê°œìˆ˜ ë°˜í™˜\"\"\"\n",
    "    if text == 0:\n",
    "        return 0\n",
    "    entries = re.findall(r'([ê°€-í£A-Za-z0-9\\s/]+?\\([ê°€-í£]{2,4}\\))', str(text))\n",
    "    unique_entries = set(entry.strip() for entry in entries if entry.strip())\n",
    "    return len(unique_entries)\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "if platform.system() == 'Windows':\n",
    "    rc('font', family='Malgun Gothic')\n",
    "elif platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "else:\n",
    "    rc('font', family='NanumGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "\n",
    "def create_dataframe_from_excel(file_path, sheet_index=0):\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    sheet_name = xls.sheet_names[sheet_index]\n",
    "    return pd.read_excel(xls, sheet_name=sheet_name, header=0)\n",
    "\n",
    "def get_excel_file_paths(data_dir):\n",
    "    return [\n",
    "        os.path.join(data_dir, f)\n",
    "        for f in os.listdir(data_dir)\n",
    "        if f.lower().endswith('.xlsx')\n",
    "    ]\n",
    "\n",
    "def remove_front_end_space(df):\n",
    "    df['í‘œì¤€ê¸°êµ¬'] = df['í‘œì¤€ê¸°êµ¬'].str.strip()\n",
    "    return df\n",
    "\n",
    "def filter_non_null_rows(df):\n",
    "    mask = df['ì†Œ'].notna() & df['ìˆœë²ˆ'].isna()\n",
    "    df.loc[mask, 'ìˆœë²ˆ'] = 0\n",
    "    def is_valid_seq(x):\n",
    "        if isinstance(x, str) and x.strip() == 'ì‹ ê·œ':\n",
    "            return True\n",
    "        return pd.notna(pd.to_numeric(x, errors='coerce'))\n",
    "    valid = df['ìˆœë²ˆ'].apply(is_valid_seq)\n",
    "    return df[df['ì†Œ'].notna() & valid]\n",
    "\n",
    "def count_names(text):\n",
    "    if text == 0:\n",
    "        return 0\n",
    "    names = re.split(r'[,]+|\\n+', text)\n",
    "    return len([n.strip() for n in names if n.strip()])\n",
    "\n",
    "def count_progress_rec(text): return 1 if text == 'ì œì •ì™„ë£Œ' else 0\n",
    "def count_progress_dev(text): return 1 if text == 'ê°œë°œì¤‘' else 0\n",
    "def count_progress_propose(text): return 1 if text == 'ì œì•ˆì¤‘' else 0\n",
    "def count_progress_plan(text): return 1 if text == 'ê³„íšì¤‘' else 0\n",
    "def count_progress_stop(text): return 1 if text == 'ê°œë°œì¤‘ë‹¨' else 0\n",
    "\n",
    "def compute_development_stage(row):\n",
    "    total = row['í‘œì¤€ê±´ìˆ˜ í•©ê³„']\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    plan, propose = row['í‘œì¤€ê³„íš ê±´ìˆ˜'], row['í‘œì¤€ì œì•ˆ ê±´ìˆ˜']\n",
    "    dev, rec = row['í‘œì¤€ê°œë°œ ê±´ìˆ˜'], row['í‘œì¤€ì™„ë£Œ ê±´ìˆ˜']\n",
    "    if (plan + propose)/total >= dev/total and (plan + propose)/total >= rec/total:\n",
    "        return (plan*0.5 + propose*0.5)/total\n",
    "    if dev/total >= rec/total:\n",
    "        return 1 + dev/total\n",
    "    return 2 + rec/total\n",
    "\n",
    "def extract_position_and_name(text):\n",
    "    entries = re.findall(r'([ê°€-í£A-Za-z0-9\\s/]+?\\([ê°€-í£]{2,4}\\))', text)\n",
    "    unique_entries = sorted(set(entry.strip() for entry in entries if entry.strip()))\n",
    "    return unique_entries\n",
    "\n",
    "def main(data_dir):\n",
    "    paths = get_excel_file_paths(data_dir)\n",
    "    df_std = create_dataframe_from_excel(paths[0])\n",
    "    df_std = remove_front_end_space(df_std)\n",
    "    df_std = filter_non_null_rows(df_std)\n",
    "    print(f\"í™”ì¼ì˜ ë°ì´í„° í–‰ìˆ˜ ==> {len(df_std)}\")\n",
    "\n",
    "    for col in ['ETRI ê¸°ê³ ì', 'ETRI ì—ë””í„°(ì˜ˆì •í¬í•¨)', 'ETRI ì˜ì¥ë‹¨']:\n",
    "        df_std[col] = df_std[col].fillna(0)\n",
    "\n",
    "    idx = df_std.columns.get_loc('ETRI ê¸°ê³ ì')\n",
    "    df_std.insert(idx+1, 'ê¸°ê³ ììˆ˜', df_std['ETRI ê¸°ê³ ì'].apply(count_names))\n",
    "    idx = df_std.columns.get_loc('ETRI ì—ë””í„°(ì˜ˆì •í¬í•¨)')\n",
    "    df_std.insert(idx+1, 'ì—ë””í„°ìˆ˜', df_std['ETRI ì—ë””í„°(ì˜ˆì •í¬í•¨)'].apply(count_names))\n",
    "    idx = df_std.columns.get_loc('ETRI ì˜ì¥ë‹¨')\n",
    "    df_std.insert(idx+1, 'ì˜ì¥ë‹¨ìˆ˜', df_std['ETRI ì˜ì¥ë‹¨'].apply(count_unique_names))\n",
    "\n",
    "    idx = df_std.columns.get_loc('í‘œì¤€í™” ìƒíƒœ')\n",
    "    df_std.insert(idx+1, 'í‘œì¤€ì™„ë£Œ ê±´ìˆ˜', df_std['í‘œì¤€í™” ìƒíƒœ'].apply(count_progress_rec))\n",
    "    df_std.insert(idx+2, 'í‘œì¤€ê°œë°œ ê±´ìˆ˜', df_std['í‘œì¤€í™” ìƒíƒœ'].apply(count_progress_dev))\n",
    "    df_std.insert(idx+3, 'í‘œì¤€ì œì•ˆ ê±´ìˆ˜', df_std['í‘œì¤€í™” ìƒíƒœ'].apply(count_progress_propose))\n",
    "    df_std.insert(idx+4, 'í‘œì¤€ê³„íš ê±´ìˆ˜', df_std['í‘œì¤€í™” ìƒíƒœ'].apply(count_progress_plan))\n",
    "    df_std.insert(idx+5, 'ê°œë°œì¤‘ë‹¨ ê±´ìˆ˜', df_std['í‘œì¤€í™” ìƒíƒœ'].apply(count_progress_stop))\n",
    "\n",
    "    df_std['ì „ëµê¸°ìˆ  ë¶„ì•¼'] = df_std['ì „ëµê¸°ìˆ  ë¶„ì•¼'].apply(\n",
    "        lambda v: re.sub(r'^(\\d)\\)', r'0\\1)', v) if isinstance(v, str) else v\n",
    "    )\n",
    "    df_std['(ì˜ˆì •) ì‹œì‘ë…„ë„  '] = df_std['(ì˜ˆì •) ì‹œì‘ë…„ë„  '].apply(\n",
    "        lambda v: f\"'{int(v)%100:02d}\" if isinstance(v, (int,float)) and float(v).is_integer() else v\n",
    "    )\n",
    "    df_std['(ì˜ˆì •) ì™„ë£Œì—°ë„'] = df_std['(ì˜ˆì •) ì™„ë£Œì—°ë„'].apply(\n",
    "        lambda v: f\"'{int(v)%100:02d}\" if isinstance(v, (int,float)) and float(v).is_integer() else v\n",
    "    )\n",
    "\n",
    "    # ============================\n",
    "    # ê°œë°œì¤‘ë‹¨ëœ í”„ë¡œì íŠ¸ ìˆ˜ ì¶œë ¥\n",
    "    stopped_count = df_std['ê°œë°œì¤‘ë‹¨ ê±´ìˆ˜'].sum()\n",
    "    print(f\"ğŸ›‘ ê°œë°œ ì¤‘ë‹¨ëœ í”„ë¡œì íŠ¸ ìˆ˜: {stopped_count}\")\n",
    "\n",
    "    # ============================\n",
    "    # ê·¸ë£¹ ì •ì˜\n",
    "    group_definitions = [\n",
    "        (['ì†Œ'], ['í‘œì¤€ì™„ë£Œ ê±´ìˆ˜','í‘œì¤€ê°œë°œ ê±´ìˆ˜','í‘œì¤€ì œì•ˆ ê±´ìˆ˜','í‘œì¤€ê³„íš ê±´ìˆ˜'], \"ì—°ì°¨ë³„í˜„í™©\"),\n",
    "        (['ì „ëµê¸°ìˆ  ë¶„ì•¼','ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼','ì†Œ','ë³¸ë¶€(ë‹¨)'], ['í‘œì¤€ì™„ë£Œ ê±´ìˆ˜','í‘œì¤€ê°œë°œ ê±´ìˆ˜','í‘œì¤€ì œì•ˆ ê±´ìˆ˜','í‘œì¤€ê³„íš ê±´ìˆ˜','ì—ë””í„°ìˆ˜','ê¸°ê³ ììˆ˜','í‘œì¤€íŠ¹í—ˆ ê°œìˆ˜'], \"í˜„í™©ì´ê´„_42ëŒ€ì¤‘ì ì„¸ë¶€\"),\n",
    "        (['ì „ëµê¸°ìˆ  ë¶„ì•¼','ì†Œ','ë³¸ë¶€(ë‹¨)','í‘œì¤€ê¸°êµ¬'], ['í‘œì¤€ì™„ë£Œ ê±´ìˆ˜','í‘œì¤€ê°œë°œ ê±´ìˆ˜','í‘œì¤€ì œì•ˆ ê±´ìˆ˜','í‘œì¤€ê³„íš ê±´ìˆ˜','ì˜ì¥ë‹¨ìˆ˜','ì—ë””í„°ìˆ˜','ê¸°ê³ ììˆ˜','í‘œì¤€íŠ¹í—ˆ ê°œìˆ˜'], \"ì£¼ìš”ì°¸ì—¬_í‘œì¤€ê¸°êµ¬\"),\n",
    "        (['ì „ëµê¸°ìˆ  ë¶„ì•¼','ì†Œ','ë³¸ë¶€(ë‹¨)','í‘œì¤€ê¸°êµ¬'], ['í‘œì¤€ì™„ë£Œ ê±´ìˆ˜','í‘œì¤€ê°œë°œ ê±´ìˆ˜','ì˜ì¥ë‹¨ìˆ˜','ì—ë””í„°ìˆ˜','ê¸°ê³ ììˆ˜','í‘œì¤€íŠ¹í—ˆ ê°œìˆ˜'], \"í‘œì¤€í™” ìˆ˜í–‰ ì—°êµ¬ë¶€ì„œ\"),\n",
    "        (['ì „ëµê¸°ìˆ  ë¶„ì•¼','ì†Œ','ë³¸ë¶€(ë‹¨)','í‘œì¤€ê¸°êµ¬'], ['í‘œì¤€íŠ¹í—ˆ ê°œìˆ˜'], \"í‘œì¤€íŠ¹í—ˆí™•ë³´\"),\n",
    "        (['ì „ëµê¸°ìˆ  ë¶„ì•¼','ì‚¬ì—…ë¶„ë¥˜'], ['ì‚¬ì—…ë¶„ë¥˜'], \"ê´€ë ¨ì‚¬ì—…í˜„í™©\"),\n",
    "        (['ì „ëµê¸°ìˆ  ë¶„ì•¼'], ['í‘œì¤€ì™„ë£Œ ê±´ìˆ˜','í‘œì¤€ê°œë°œ ê±´ìˆ˜','í‘œì¤€ì œì•ˆ ê±´ìˆ˜','í‘œì¤€ê³„íš ê±´ìˆ˜','ì˜ì¥ë‹¨ìˆ˜','ì—ë””í„°ìˆ˜','í‘œì¤€íŠ¹í—ˆ ê°œìˆ˜'], \"ë¶€ë¡II_12ëŒ€ì „ëµ\"),\n",
    "    ]\n",
    "\n",
    "    grouped_dfs = []\n",
    "    for group_cols, agg_cols, name in group_definitions:\n",
    "        if name == \"ê´€ë ¨ì‚¬ì—…í˜„í™©\":\n",
    "            grouped = (\n",
    "                df_std.groupby(['ì „ëµê¸°ìˆ  ë¶„ì•¼', 'ì‚¬ì—…ë¶„ë¥˜'], as_index=False)\n",
    "                .size()\n",
    "                .rename(columns={'size': 'ì‚¬ì—…ë¶„ë¥˜ìˆ˜'})\n",
    "            )\n",
    "        else:\n",
    "            grouped = df_std.groupby(group_cols, as_index=False)[agg_cols].sum()\n",
    "        grouped_dfs.append((grouped, name))\n",
    "\n",
    "    # ============================\n",
    "    # ì˜ì¥ë‹¨ ìš”ì•½\n",
    "    strategic_df = df_std[['ì „ëµê¸°ìˆ  ë¶„ì•¼', 'ETRI ì˜ì¥ë‹¨']].copy()\n",
    "    strategic_df['ETRI ì˜ì¥ë‹¨'] = strategic_df['ETRI ì˜ì¥ë‹¨'].fillna('').astype(str).str.strip()\n",
    "    strategic_df = strategic_df[(strategic_df['ETRI ì˜ì¥ë‹¨'] != '') & (strategic_df['ETRI ì˜ì¥ë‹¨'] != '0') & (strategic_df['ETRI ì˜ì¥ë‹¨'] != '-')]\n",
    "    strategic_chairs = strategic_df.groupby('ì „ëµê¸°ìˆ  ë¶„ì•¼')['ETRI ì˜ì¥ë‹¨'].apply(lambda x: ', '.join(x)).reset_index().rename(columns={'ETRI ì˜ì¥ë‹¨': 'ì˜ì¥ë‹¨ ëª©ë¡'})\n",
    "    strategic_chairs['ì˜ì¥ë‹¨ ê³ ìœ ëª…ë‹¨'] = strategic_chairs['ì˜ì¥ë‹¨ ëª©ë¡'].apply(lambda x: ', '.join(extract_position_and_name(x)))\n",
    "    strategic_chairs['ì˜ì¥ë‹¨ ê³ ìœ ì¸ì›ìˆ˜'] = strategic_chairs['ì˜ì¥ë‹¨ ê³ ìœ ëª…ë‹¨'].apply(lambda x: len([n for n in x.split(',') if n.strip()]))\n",
    "\n",
    "    org_df = df_std[['í‘œì¤€ê¸°êµ¬', 'ETRI ì˜ì¥ë‹¨']].copy()\n",
    "    org_df['ETRI ì˜ì¥ë‹¨'] = org_df['ETRI ì˜ì¥ë‹¨'].fillna('').astype(str).str.strip()\n",
    "    org_df = org_df[(org_df['ETRI ì˜ì¥ë‹¨'] != '') & (org_df['ETRI ì˜ì¥ë‹¨'] != '0') & (org_df['ETRI ì˜ì¥ë‹¨'] != '-')]\n",
    "    org_chairs = org_df.groupby('í‘œì¤€ê¸°êµ¬')['ETRI ì˜ì¥ë‹¨'].apply(lambda x: ', '.join(x)).reset_index().rename(columns={'ETRI ì˜ì¥ë‹¨': 'ì˜ì¥ë‹¨ ëª©ë¡'})\n",
    "    org_chairs['ì˜ì¥ë‹¨ ê³ ìœ ëª…ë‹¨'] = org_chairs['ì˜ì¥ë‹¨ ëª©ë¡'].apply(lambda x: ', '.join(extract_position_and_name(x)))\n",
    "    org_chairs['ì˜ì¥ë‹¨ ê³ ìœ ì¸ì›ìˆ˜'] = org_chairs['ì˜ì¥ë‹¨ ê³ ìœ ëª…ë‹¨'].apply(lambda x: len([n for n in x.split(',') if n.strip()]))\n",
    "\n",
    "    # ============================\n",
    "    # grouped15 (í‘œì¤€í™” ë‹¨ê³„)\n",
    "    grouped15 = df_std.groupby(['ì „ëµê¸°ìˆ  ë¶„ì•¼','ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼'], as_index=False)[\n",
    "        ['í‘œì¤€ê³„íš ê±´ìˆ˜','í‘œì¤€ì œì•ˆ ê±´ìˆ˜','í‘œì¤€ê°œë°œ ê±´ìˆ˜','í‘œì¤€ì™„ë£Œ ê±´ìˆ˜','ì˜ì¥ë‹¨ìˆ˜','ì—ë””í„°ìˆ˜','ê¸°ê³ ììˆ˜']\n",
    "    ].sum()\n",
    "    grouped15['í‘œì¤€ê±´ìˆ˜ í•©ê³„'] = grouped15[['í‘œì¤€ê³„íš ê±´ìˆ˜','í‘œì¤€ì œì•ˆ ê±´ìˆ˜','í‘œì¤€ê°œë°œ ê±´ìˆ˜','í‘œì¤€ì™„ë£Œ ê±´ìˆ˜']].sum(axis=1)\n",
    "    grouped15['í‘œì¤€ê°œë°œ ë‹¨ê³„'] = grouped15.apply(compute_development_stage, axis=1)\n",
    "    grouped15['í‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’'] = (\n",
    "        np.log(1 + grouped15['ì˜ì¥ë‹¨ìˆ˜']*0.1) +\n",
    "        np.log(1 + grouped15['ì—ë””í„°ìˆ˜']*0.2) +\n",
    "        np.log(1 + grouped15['ê¸°ê³ ììˆ˜']*0.7)\n",
    "    ) / 100\n",
    "    max_by_field = grouped15[~grouped15['ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼'].str.contains('ê¸°íƒ€')].groupby('ì „ëµê¸°ìˆ  ë¶„ì•¼')['í‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’'].transform('max')\n",
    "    grouped15['í‘œì¤€í™” ì—­ëŸ‰'] = (grouped15['í‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’'] / max_by_field) * 3\n",
    "\n",
    "    grouped15['norm_dev_stage'] = (grouped15['í‘œì¤€ê°œë°œ ë‹¨ê³„'] - grouped15['í‘œì¤€ê°œë°œ ë‹¨ê³„'].min()) / (grouped15['í‘œì¤€ê°œë°œ ë‹¨ê³„'].max() - grouped15['í‘œì¤€ê°œë°œ ë‹¨ê³„'].min())\n",
    "    grouped15['norm_capability'] = (grouped15['í‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’'] - grouped15['í‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’'].min()) / (grouped15['í‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’'].max() - grouped15['í‘œì¤€í™” ì—­ëŸ‰ ê³„ì‚°ê°’'].min())\n",
    "    grouped15['ì¢…í•©í™œë™ ì ìˆ˜'] = 0.5 * grouped15['norm_dev_stage'] + 0.5 * grouped15['norm_capability']\n",
    "    grouped15['ì¢…í•©í™œë™ ì ìˆ˜(5ì ì²™ë„)'] = (grouped15['ì¢…í•©í™œë™ ì ìˆ˜'] * 5).round(0).astype(int)\n",
    "\n",
    "    grouped_dfs.append((grouped15, \"42ëŒ€ì¤‘ì _ì „ëµ\"))\n",
    "    \n",
    "    # ============================\n",
    "    # Excel íŒŒì¼ í†µí•© ì €ì¥\n",
    "    output_excel_path = os.path.join(output_dir, \"í†µí•©_ì¶œë ¥íŒŒì¼.xlsx\")\n",
    "    with pd.ExcelWriter(output_excel_path, engine=\"openpyxl\") as writer:\n",
    "        df_std.to_excel(writer, sheet_name=\"ì „ì²´ë°ì´í„°\", index=False)\n",
    "        for df, name in grouped_dfs:\n",
    "            df.to_excel(writer, sheet_name=name, index=False)\n",
    "        strategic_chairs.to_excel(writer, sheet_name=\"ì „ëµ_ì˜ì¥ë‹¨\", index=False)\n",
    "        org_chairs.to_excel(writer, sheet_name=\"í‘œì¤€ê¸°êµ¬_ì˜ì¥ë‹¨\", index=False)\n",
    "        grouped15.to_excel(writer, sheet_name=\"42ëŒ€ì¤‘ì _ì „ëµ\", index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "    print(f\"âœ… Excel í†µí•© íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_excel_path}\")\n",
    "\n",
    "    # ============================\n",
    "    # ê·¸ë˜í”„ ì €ì¥\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for tech, data in grouped15.groupby('ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼'):\n",
    "        plt.scatter(data['í‘œì¤€ê°œë°œ ë‹¨ê³„'], data['í‘œì¤€í™” ì—­ëŸ‰'], label=tech, alpha=0.7)\n",
    "    plt.xlabel('í‘œì¤€ê°œë°œ ë‹¨ê³„', fontsize=12)\n",
    "    plt.ylabel('í‘œì¤€í™” ì—­ëŸ‰', fontsize=12)\n",
    "    plt.title('ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼ë³„ í‘œì¤€ê°œë°œ ë‹¨ê³„ì™€ í‘œì¤€í™” ì—­ëŸ‰', fontsize=14)\n",
    "    plt.xlim(0, 3.5)\n",
    "    plt.ylim(0, 3.5)\n",
    "    plt.legend(title='ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼', bbox_to_anchor=(1.05,1), loc='upper left', fontsize=10)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    save_figure(plt, \"graph_output\")\n",
    "    plt.show()\n",
    "\n",
    "    strategic_fields = grouped15['ì „ëµê¸°ìˆ  ë¶„ì•¼'].unique()\n",
    "    for field in strategic_fields:\n",
    "        df_field = grouped15[grouped15['ì „ëµê¸°ìˆ  ë¶„ì•¼'] == field]\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for tech, data in df_field.groupby('ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼'):\n",
    "            plt.scatter(data['í‘œì¤€ê°œë°œ ë‹¨ê³„'], data['í‘œì¤€í™” ì—­ëŸ‰'], label=tech, alpha=0.7)\n",
    "            for idx, row in df_field.iterrows():\n",
    "                plt.annotate(\n",
    "                    row['ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼'],\n",
    "                    (row['í‘œì¤€ê°œë°œ ë‹¨ê³„'], row['í‘œì¤€í™” ì—­ëŸ‰']),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(5, 5),\n",
    "                    ha='left',\n",
    "                    fontsize=9\n",
    "                )\n",
    "        plt.xlabel('í‘œì¤€ê°œë°œ ë‹¨ê³„', fontsize=12)\n",
    "        plt.ylabel('í‘œì¤€í™” ì—­ëŸ‰', fontsize=12)\n",
    "        plt.title(f\"[{field}] ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼ë³„ í‘œì¤€ê°œë°œ ë‹¨ê³„ì™€ í‘œì¤€í™” ì—­ëŸ‰\", fontsize=14)\n",
    "        plt.xlim(0, 3.5)\n",
    "        plt.ylim(0, 3.5)\n",
    "        plt.legend(title='ì„¸ë¶€ì¤‘ì ê¸°ìˆ  ë¶„ì•¼', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        save_figure(plt, f\"graph_output_{field}\")\n",
    "        plt.close()\n",
    "    print(\"ëª¨ë“  ì „ëµê¸°ìˆ  ë¶„ì•¼ë³„ ê·¸ë¦¼ì´ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = 'data'\n",
    "    main(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9d804-8341-429c-8d2c-373255d18bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1f98b-a17d-4494-a129-68ab6b42275d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
